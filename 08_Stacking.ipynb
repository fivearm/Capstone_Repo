{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, plot_confusion_matrix, confusion_matrix\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('Data/X_train.csv', index_col='building_id')\n",
    "X_test = pd.read_csv('Data/X_test.csv', index_col='building_id')\n",
    "y_train = pd.read_csv('Data/y_train.csv', index_col='building_id')\n",
    "y_test = pd.read_csv('Data/y_test.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, X_train_leftover, y_train_sample, y_train_leftover = \\\n",
    "    train_test_split(X_train, y_train, test_size=.9, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide Columns and drop unimportant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, I'll divide the columns for the Pipeline and drop unimportant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = []\n",
    "for col in X_train.columns:\n",
    "    if col.startswith('has'):\n",
    "        binary_cols.append(col)\n",
    "\n",
    "cat_cols = list(X_train.select_dtypes(include='object').columns)\n",
    "\n",
    "integer_cols = ['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage', 'count_families']\n",
    "\n",
    "geo_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "\n",
    "all_cols = geo_cols + cat_cols + integer_cols + binary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols_dropped = binary_cols.copy()\n",
    "for col in binary_cols_dropped:\n",
    "    if col.startswith('has_secondary'):\n",
    "        binary_cols_dropped.remove(col)\n",
    "binary_cols_dropped.append('has_secondary_use')\n",
    "\n",
    "cat_cols_dropped = cat_cols.copy()\n",
    "cat_cols_dropped.remove('legal_ownership_status')\n",
    "cat_cols_dropped.remove('plan_configuration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan is to use Random Forest and KNN as the estimators and LogisticRegression as the final estimator in the stacked model.  First, I will need to create pipelines for the various column transformations for RF and KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(x):\n",
    "    return np.log(x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the intial Pipelines for OHE, Target Encoding, log transform, and Standard Scaler\n",
    "ohe_pipe = imbPipeline([('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "target_pipe = imbPipeline([('target', TargetEncoder(cols=geo_cols))])\n",
    "\n",
    "function_transformer = FunctionTransformer(log_transform)\n",
    "integer_pipe = imbPipeline([\n",
    "    ('function', function_transformer),\n",
    "    ('ss', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Random Forest ColumnTransformer and final pipeline\n",
    "rf_preprocessor = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols_dropped),\n",
    "    ('categorical', ohe_pipe, cat_cols_dropped),\n",
    "    ('integer', 'passthrough', integer_cols),\n",
    "    ('geo', target_pipe, geo_cols)\n",
    "])\n",
    "\n",
    "rf_pipe = imbPipeline([\n",
    "    ('rf_preprocessor', rf_preprocessor),\n",
    "    ('rf', RandomForestClassifier(max_depth=50, min_samples_split=10, n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the KNN ColumnTransformer and final pipeline\n",
    "knn_preprocessor = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols_dropped),\n",
    "    ('categorical', ohe_pipe, cat_cols_dropped),\n",
    "    ('geo', target_pipe, geo_cols),\n",
    "    ('integer', integer_pipe, integer_cols),\n",
    "])\n",
    "\n",
    "knn_pipe = imbPipeline([\n",
    "    ('knn_preprocessor', knn_preprocessor),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=75, p=1, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg_preprocessor = ColumnTransformer([\n",
    "#    ('binary', 'passthrough', binary_cols_dropped),\n",
    "#    ('categorical', ohe_pipe, cat_cols_dropped),\n",
    "#    ('geo', target_pipe, geo_cols),\n",
    "#    ('integer', integer_pipe, integer_cols),\n",
    "#])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Stacking Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('rf', rf_pipe),\n",
    "              ('knn', knn_pipe)]\n",
    "final_estimator = LogisticRegression(C=.01, solver='saga', n_jobs=-1, random_state=42)\n",
    "\n",
    "stacked = StackingClassifier(estimators=estimators, final_estimator=final_estimator, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the stacked models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "stacked.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f'Runtime: {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_preds = stacked.predict(X_test)\n",
    "stacked_score = f1_score(y_test, stacked_preds, average='micro')\n",
    "stacked_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
