{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, plot_confusion_matrix, confusion_matrix\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('Data/X_train.csv', index_col='building_id')\n",
    "X_test = pd.read_csv('Data/X_test.csv', index_col='building_id')\n",
    "y_train = pd.read_csv('Data/y_train.csv', index_col='building_id')\n",
    "y_test = pd.read_csv('Data/y_test.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = []\n",
    "for col in X_train.columns:\n",
    "    if col.startswith('has'):\n",
    "        binary_cols.append(col)\n",
    "\n",
    "cat_cols = list(X_train.select_dtypes(include='object').columns)\n",
    "\n",
    "integer_cols = ['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage', 'count_families']\n",
    "\n",
    "geo_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "\n",
    "all_cols = geo_cols + cat_cols + integer_cols + binary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {}\n",
    "def print_scores():\n",
    "    for key in score_dict.keys():\n",
    "        print(f'{key}, f1_micro_score: {round(score_dict[key][0],4)}, Run time: {round(score_dict[key][1],0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logreg0:  Basline Logistic Regression with no feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_pipe = imbPipeline([('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols),\n",
    "    ('categorical', ohe_pipe, cat_cols),\n",
    "    ('integer', 'passthrough', integer_cols),\n",
    "    ('geo', 'passthrough', geo_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg0_pipe = imbPipeline([\n",
    "    ('trans', transformer), \n",
    "    ('logreg', LogisticRegression(n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 78.13385510444641\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "f1_micro_logreg0 = cross_val_score(logreg0_pipe, X_train, y_train, scoring='f1_micro')\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')\n",
    "run_time_logreg0 = (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5691174213353799"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg0 = f1_micro_logreg0.mean()\n",
    "f1_micro_logreg0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg0, f1_micro_score: 0.5691, Run time: 78.0\n"
     ]
    }
   ],
   "source": [
    "score_dict['logreg0'] = [f1_micro_logreg0, run_time_logreg0]\n",
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a great score compared to our Random Forest models.  Let's move on with some feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logreg1: Try normalizing and scaling integer columns and dropping some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will drop the same features that I did for the random forest model after checking feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols_dropped = binary_cols.copy()\n",
    "for col in binary_cols_dropped:\n",
    "    if col.startswith('has_secondary'):\n",
    "        binary_cols_dropped.remove(col)\n",
    "binary_cols_dropped.append('has_secondary_use')\n",
    "\n",
    "cat_cols_dropped = cat_cols.copy()\n",
    "cat_cols_dropped.remove('legal_ownership_status')\n",
    "cat_cols_dropped.remove('plan_configuration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def log_transform(x):\n",
    "    return np.log(x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "ohe_pipe = imbPipeline([('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "integer_pipe = imbPipeline([\n",
    "    ('function', function_transformer),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols_dropped),\n",
    "    ('categorical', ohe_pipe, cat_cols_dropped),\n",
    "    ('geo', 'passthrough', geo_cols),\n",
    "    ('integer', integer_pipe, integer_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg1_pipe = imbPipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('logreg', LogisticRegression(n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 59.065468072891235\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "f1_micro_logreg1 = cross_val_score(logreg1_pipe, X_train, y_train, scoring='f1_micro')\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')\n",
    "run_time_logreg1 = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5723151701202354"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg1 = f1_micro_logreg1.mean()\n",
    "f1_micro_logreg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg0, f1_micro_score: 0.5691, Run time: 78.0\n",
      "logreg1, f1_micro_score: 0.5723, Run time: 59.0\n"
     ]
    }
   ],
   "source": [
    "score_dict['logreg1'] = [f1_micro_logreg1, run_time_logreg1]\n",
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a slight improvement.  Let's keep the scaling and normalization and add Target Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logreg2:  Try Target Encoding on the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "ohe_pipe = imbPipeline([('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "integer_pipe = imbPipeline([\n",
    "    ('function', function_transformer),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "target_pipe = imbPipeline([('target', TargetEncoder(cols=geo_cols))])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols_dropped),\n",
    "    ('categorical', ohe_pipe, cat_cols_dropped),\n",
    "    ('geo', target_pipe, geo_cols),\n",
    "    ('integer', integer_pipe, integer_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2_pipe = imbPipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('logreg', LogisticRegression(n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 57.024518966674805\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "f1_micro_logreg2 = cross_val_score(logreg2_pipe, X_train, y_train, scoring='f1_micro')\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')\n",
    "run_time_logreg2 = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7267587618316704"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg2 = f1_micro_logreg2.mean()\n",
    "f1_micro_logreg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg0, f1_micro_score: 0.5691, Run time: 78.0\n",
      "logreg1, f1_micro_score: 0.5723, Run time: 59.0\n",
      "logreg2, f1_micro_score: 0.7268, Run time: 57.0\n"
     ]
    }
   ],
   "source": [
    "score_dict['logreg2'] = [f1_micro_logreg2, run_time_logreg2]\n",
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Encoding greatly improves the model.  In fact, the f1-micro score is similar to the Random Forest models, with less run time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logreg3:  Use previous model with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "ohe_pipe = imbPipeline([('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "integer_pipe = imbPipeline([\n",
    "    ('function', function_transformer),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "target_pipe = imbPipeline([('target', TargetEncoder(cols=geo_cols))])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols_dropped),\n",
    "    ('categorical', ohe_pipe, cat_cols_dropped),\n",
    "    ('geo', target_pipe, geo_cols),\n",
    "    ('integer', integer_pipe, integer_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg3_pipe = imbPipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('logreg', LogisticRegression(n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 55.64549922943115\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "f1_micro_logreg3 = cross_val_score(logreg2_pipe, X_train, y_train, scoring='f1_micro')\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')\n",
    "run_time_logreg3 = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7267587618316704"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg3 = f1_micro_logreg3.mean()\n",
    "f1_micro_logreg3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg0, f1_micro_score: 0.5691, Run time: 78.0\n",
      "logreg1, f1_micro_score: 0.5723, Run time: 59.0\n",
      "logreg2, f1_micro_score: 0.7268, Run time: 57.0\n",
      "logreg3, f1_micro_score: 0.7268, Run time: 56.0\n"
     ]
    }
   ],
   "source": [
    "score_dict['logreg3'] = [f1_micro_logreg3, run_time_logreg3]\n",
    "print_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg2 == f1_micro_logreg3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SMOTE does not change the f1-micro score, so I will not use it going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the model with GridsearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a small grid search to see if we can improve the model.  I'll use logreg2 as the estimator, since it's the best model so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 132.1313660144806\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "logreg_pipe_grid = {'logreg__C': [1e-3, 1e-2, 1, 1e2],\n",
    "                   'logreg__solver': ['lbfgs', 'saga']}\n",
    "logreg_gs = GridSearchCV(estimator=logreg2_pipe, param_grid=logreg_pipe_grid, \n",
    "                              scoring='f1_micro', verbose=1, cv=2)\n",
    "logreg_gs.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 0.01, 'logreg__solver': 'saga'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7227526221540035"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logreg4:  Use the grid searched hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use C=.01 and solver='saga'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "ohe_pipe = imbPipeline([('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "integer_pipe = imbPipeline([\n",
    "    ('function', function_transformer),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "target_pipe = imbPipeline([('target', TargetEncoder(cols=geo_cols))])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols_dropped),\n",
    "    ('categorical', ohe_pipe, cat_cols_dropped),\n",
    "    ('geo', target_pipe, geo_cols),\n",
    "    ('integer', integer_pipe, integer_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(transformers=[('binary', 'passthrough',\n",
       "                                                  ['has_superstructure_adobe_mud',\n",
       "                                                   'has_superstructure_mud_mortar_stone',\n",
       "                                                   'has_superstructure_stone_flag',\n",
       "                                                   'has_superstructure_cement_mortar_stone',\n",
       "                                                   'has_superstructure_mud_mortar_brick',\n",
       "                                                   'has_superstructure_cement_mortar_brick',\n",
       "                                                   'has_superstructure_timber',\n",
       "                                                   'has_superstr...\n",
       "                                                  ['geo_level_1_id',\n",
       "                                                   'geo_level_2_id',\n",
       "                                                   'geo_level_3_id']),\n",
       "                                                 ('integer',\n",
       "                                                  Pipeline(steps=[('function',\n",
       "                                                                   FunctionTransformer(func=<function log_transform at 0x7fb5a747e4c0>)),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['count_floors_pre_eq', 'age',\n",
       "                                                   'area_percentage',\n",
       "                                                   'height_percentage',\n",
       "                                                   'count_families'])])),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=0.01, n_jobs=-1, random_state=42,\n",
       "                                    solver='saga'))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg4_pipe = imbPipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('logreg', LogisticRegression(C=.01, solver='saga', n_jobs=-1, random_state=42))\n",
    "])\n",
    "\n",
    "logreg4_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 26.932199239730835\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "f1_micro_logreg4 = cross_val_score(logreg4_pipe, X_train, y_train, scoring='f1_micro')\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')\n",
    "run_time_logreg4 = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7273931951905859"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg4 = f1_micro_logreg4.mean()\n",
    "f1_micro_logreg4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg0, f1_micro_score: 0.5691, Run time: 78.0\n",
      "logreg1, f1_micro_score: 0.5723, Run time: 59.0\n",
      "logreg2, f1_micro_score: 0.7268, Run time: 57.0\n",
      "logreg3, f1_micro_score: 0.7268, Run time: 56.0\n",
      "logreg4, f1_micro_score: 0.7274, Run time: 27.0\n"
     ]
    }
   ],
   "source": [
    "score_dict['logreg4'] = [f1_micro_logreg4, run_time_logreg4]\n",
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is only a marginal score improvement, the saga solver does reduce the runtime by about half.  Let's call this the final Logistic Regression Model and check the model's performance on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the final model's performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7305490322481619"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg4_preds = logreg4_pipe.predict(X_test)\n",
    "logreg4_test_score = f1_score(y_test, logreg4_preds, average='micro')\n",
    "logreg4_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not quite at the level of the Random Forest Classfier, this model performs remarkably well for it's speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix and check model's target accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEGCAYAAADyuIefAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAspUlEQVR4nO3dd3xUVfr48c+TQhJICL13KVJWQBGxLoIrdrGwoq6gy4rrYl3dXdvvK+ri2l3RlRVFRaxYdsVVREUURKSKdASlg4EEkkAIKTPP7497EoaQMkPKzITn/XrdV+6cOefec6/4zCm3iKpijDHGExPuChhjTCSxoGiMMQEsKBpjTAALisYYE8CCojHGBIgLdwUC1YlN0qS4+uGuRuQSCXcNIp7m5Ye7ChHtADnka16l/iENObOeZuz2BZV38bK8Gap6TmX2V9MiKigmxdXnlBZXhbsaEUsT64S7ChHPt+7ncFchos3XmZXeRsZuHwtmtAsqb2zLdU0qvcMaFlFB0RgT+RTw4w93NaqNBUVjTEgUpUCD6z5HIwuKxpiQWUvRGGMcRfHV4tuD7ZIcY0zI/GhQS3lEJFFEFojIDyKyUkQecOmNRORzEVnn/jYMKHO3iKwXkbUiMiQg/QQRWe6+Gy/iXaohIgki8o5Lny8iHSo6NguKxpiQKOBDg1oqkAcMUtXeQB/gHBEZANwFzFTVLsBM9xkR6QEMB3oC5wDPi0is29YEYDTQxS1FlwGNAvaoamfgaeDRiiplQdEYE7KqaCmqZ5/7GO8WBS4GJrv0ycBQt34x8Laq5qnqBmA90F9EWgL1VXWeeo/9eq1EmaJtvQcMLmpFlsWCojEmJAoUqAa1VEREYkVkKbAT+FxV5wPNVXUHgPvbzGVvDWwJKL7VpbV26yXTDymjqoVAFtC4vDrZRIsxJiQaXNe4SBMRWRTweaKqTizelqoP6CMiDYD/iEivcrZVWgtPy0kvr0yZLCgaY0Kj4At+8jldVftVuEnVTBH5Cm8sME1EWqrqDtc13umybQXaBhRrA2x36W1KSQ8ss1VE4oBUYHd5dbHuszEmJN4dLcEt5RGRpq6FiIgkAWcBa4BpwEiXbSTwoVufBgx3M8od8SZUFrgu9l4RGeDGC0eUKFO0rcuBL7WC1w1YS9EYEyLBV2qvNGQtgcluBjkGmKqq/xORecBUERkFbAaGAajqShGZCqwCCoExrvsNcCPwKpAETHcLwCRgioisx2shDq+oUhYUjTEh8SZaKh8UVXUZ0LeU9AxgcBllxgHjSklfBBw2HqmqB3BBNVgWFI0xIfGuU6y9j7GzoGiMCZm/ClqKkcqCojEmJNZSNMaYAIrgq8UXrlhQNMaEzLrPxhjjKEK+xlacMUpZUDTGhMS7eNu6z8YYU8wmWowxxlEVfGotRWOMKea3lqIxxni8iZbaGzpq75EZY6qFTbQYY0wJPrtO0RhjPHZHizHGlOC32WdjjPF4D4SwoGiMMYDXfS6w2/xqhybNcrlj7FIaNsrDr8Kn/23HtHc6AnDhsA1cMGwTPp+wcG4zXnmuO3Fxfm66ezldjs3CrzDxqZ4sX+K9HTEuzs+Nf1nBr47fjd8Pr/27G9/OahnOw6u0+Do+Hhs/h/h4H7Gxyjdft+aNV7oXf3/pFev4w59WMPyi88jOSiAuzs/Nd35Pl26Z+P3wwrPHsXxpU8Cdn9t+4Lg+u/D7hdde6sHc2a3L2nWtcMn1uzj3qgxUhQ1rEnny9ra0PSaPmx/ZSlI9P2lb6/DomHbs3xfdAUUVu3j7SIjIy8AFwE5VLe+1hTXG5xNeeqYHP61NJaluIc9M/obvFzShYaM8BpyRxpirT6ewIJbUhnkADBm6GYAxV59BasM8HvznAm679jRUhSuuW0/m7gRGDxuIiJJSvyCch1YlCvJjuPv20ziQG0dsrJ8nnpvNovnNWbuqEU2a7qdvv53s/CWpOP85F2wE4E/XDSa1QR4PPvYtt90w0Ds/16wla08C1//ubHd+8sN0VDWjcYsCho5K5/qB3cg/EMO9/97IwIszufDadF58sBXLv0vm7OEZXH7jTl57PLp/PEFq9cXb1RnuX8V7XWHE2JORyE9rUwHI3R/Hlo3JNG56gPMu3cy7r3WmsMD7Bc/akwBAu477+GFh4+K0fXvj6dI9C4DfXLiFqZOPAbzbnrKz6tT04VQD4UCu9zsZF+cnNs5f/Ibc0Tct5+V/90IDLsVo1yGbpYu9lmFWZgI5++Lp0m0PAGeft4l33ugKFJ2fhBo8jvCIjVMSEv3ExCoJSX4y0uJpc0wey7+rB8D3s1M47fysMNey8hSvpRjMEo2qrdaqOpsK3q8aTs1a7qdT1yzWrmxA63Y59Oyzm6cmzeWRCfPo0j0TgA3r6jPgjDRiYv00b7mfzsdm0aR5LvWSvVbhNTf8yDOT53D3w4tp0CgvjEdTdWJilGdf+pI3//sJ3y9qxtrVjTjplB1kpCex4afUQ/L+/FMqA07b4Z2fFjl07ppJ02a51Ev2WoUjRq1i/ItfcvcD82nQ8EA4DqfGZPwSz3sTmjJl4WreWrqSnL2xLPk6hU1rEzl5SDYAp1+QRdNW0d+jAG+iJZglGkVnrSspMamQex9ZzItP9yA3J56YWD/JKQX8edQpvPxsd+56eAmgfPZRG9J3JvHMq3MZ/edVrF7eEL9PiI1VmjY/wKplDbl15OmsXt6QUbesDvdhVQm/X7j5D4MYMewcunbfQ4dOWQy/Zi1TXu5+WN7PPmnvnZ8XvmL0zctYvbIRvqLz0yyXVcsbc8v1g1izshF/+NOKMBxNzUlOLeTkIdmMPKk7V/XtSWJdP4Mu3cNTf27Lhdem89ynP5KU7KMwP/q7nYrg1+CWaBT2iRYRGQ2MBkiMTan2/cXG+rnnkcXM+rQ1337lje1k7Ezi269aAMKPqxqgfqF+g3yyMxN48Z89iss+8eJctm2pR3ZWPAdyY5n3VQsAvpnZkrMv2lLtda9JOfvqsPz7Jpx82g6at8zhX5O+BKBJ01zGvziL2/84kD27E3nxX8cVl3niX1+zbWsy2Vl1OJAby7dzWgEwZ1Zrzj5vU1iOo6b0PX0fv2ypQ9Zu73+puZ+k0qNfDl9+0JB7rvSGWVp3yuOkwdnhrGaV8F5xGvbQUW3C3lJU1Ymq2k9V+9WJTaq4QOX2xq33LWPLxmT++1an4tR5Xzend790AFq13UdcvJ/szDokJPhISCwEoE//Xfh8MWzZkAII879pxq+Oz/C+OzGdLRuSq7nu1a9+al5x17dOHR99+u3ip3WpXDX0fK4bPoTrhg8hfVcSt1x/Jnt2J5KQUFh8fvr224nfJ2zZVB8Q5n/bguP6eOe0zwm72Lyp+n/wwmnntni6H59DQpIfUPqcto/N6xNIbex1l0WUq25N439TGoe3olVC8AW5RKPaG+5L0aP3Hgaft40N61J4dsocACZP6MbnH7Xltvt+4F9vfk1hQQxPPdAbEFIb5fHQMwtQP2TsSuSJsb2Lt/XKc8dy59gfGH37KrIy6/DPh3qXsdfo0ajxAe64ZzExMYqIMuerNiyYV/ZMaWrDPP7++Lf4FTJ2JfHEuH7F373yQi/uvHcRo29eRlZmAk8/cnxNHELYrP2+HnM+bsC/ZvyIr1BYvyKJ6a835vxrMrjwWu/HYe70VD57u1GYa1p5Su2+o0VUtXo2LPIWMBBoAqQB96vqpPLKpCY011NaXFUt9akNNLE2zHBXL9+6n8NdhYg2X2eSrbsr1YRr0ytVx0w9Nai89/ScvlhV+1WcM3JU5+zzlaraUlXjVbVNRQHRGBMdVAW/xgS1lEdE2orILBFZLSIrReRWlz5WRLaJyFK3nBdQ5m4RWS8ia0VkSED6CSKy3H03XkTEpSeIyDsufb6IdKjo+I6q7rMxpvK8iZYquSunELhDVZeISAqwWEQ+d989rapPBGYWkR7AcKAn0Ar4QkS6qqoPmIA3Yfsd8AneNdLTgVHAHlXtLCLDgUeBK8qrVO0dGDDGVBOpkou3VXWHqi5x63uB1UB594JeDLytqnmqugFYD/QXkZZAfVWdp9544GvA0IAyk936e8DgolZkWSwoGmNC4k20BH2dYhMRWRSwjC5tm65b2xeY75JuEpFlIvKyiDR0aa2BwGvftrq01m69ZPohZVS1EMgCyr0EwLrPxpiQhXC3SnpFEy0ikgy8D9ymqtkiMgF4CC/+PgQ8CfweSr3GR8tJp4LvSmUtRWNMSKryjhYRiccLiG+o6gcAqpqmqj5V9QMvAv1d9q1A24DibYDtLr1NKemHlBGROCCVCm4/tqBojAmZn5iglvK4sb1JwGpVfSogPfDi2EuAontEpwHD3YxyR6ALsEBVdwB7RWSA2+YI4MOAMiPd+uXAl1rBdYjWfTbGhEQVCvxV0p46FbgGWC4iS13aPcCVItIHr5u7EbjB26+uFJGpwCq8mesxbuYZ4Ea8J3Ml4c06T3fpk4ApIrIer4U4vKJKWVA0xoTE6z5XPiiq6jeUPub3STllxgHjSklfBBz23FZVPQAMC6VeFhSNMSGL1vuag2FB0RgTkqJLcmorC4rGmBBVTfc5UllQNMaErDa/o8WCojEmJN7sc3S/kbA8FhSNMSEpuni7trKgaIwJmXWfjTHGsdlnY4wpwWafjTHGURUKLSgaY8xB1n02xhjHxhSNMaYEC4rGGOPYdYrGGFOCXadojDGOKhRWzUNmI5IFRWNMyKz7bIwxjo0pGmNMCWpB0RhjDrKJFmOMcVRtTNEYYwIIPpt9NsaYg2xMsaYU+vBnZoW7FhFr+to54a5CxDv3vKvCXYWIJmvmVnobdu+zMcYEUm9csbayoGiMCVltnn2uvaOlxphqoW6iJZilPCLSVkRmichqEVkpIre69EYi8rmIrHN/GwaUuVtE1ovIWhEZEpB+gogsd9+NFxFx6Qki8o5Lny8iHSo6PguKxpiQqQa3VKAQuENVuwMDgDEi0gO4C5ipql2Ame4z7rvhQE/gHOB5ESl61+oEYDTQxS3nuPRRwB5V7Qw8DTxaUaUsKBpjQqYqQS3lb0N3qOoSt74XWA20Bi4GJrtsk4Ghbv1i4G1VzVPVDcB6oL+ItATqq+o8VVXgtRJlirb1HjC4qBVZFhtTNMaExGsFBj2m2EREFgV8nqiqE0tmct3avsB8oLmq7vD2pTtEpJnL1hr4LqDYVpdW4NZLpheV2eK2VSgiWUBjIL2sCltQNMaELIRLctJVtV95GUQkGXgfuE1Vs8tpyJX2hZaTXl6ZMln32RgTsioaU0RE4vEC4huq+oFLTnNdYtzfnS59K9A2oHgbYLtLb1NK+iFlRCQOSAV2l1cnC4rGmJAogt8fE9RSHje2NwlYrapPBXw1DRjp1kcCHwakD3czyh3xJlQWuK72XhEZ4LY5okSZom1dDnzpxh3LZN1nY0zIquja7VOBa4DlIrLUpd0DPAJMFZFRwGZgGICqrhSRqcAqvJnrMarqc+VuBF4FkoDpbgEv6E4RkfV4LcThFVXKgqIxJjShTbSUvRnVbyh9zA9gcBllxgHjSklfBPQqJf0ALqgGy4KiMSZ0dpufMcYcdFQ+JUdEnqWc3wNVvaVaamSMiWgK+P1HYVAEFpXznTHmaKXA0dhSVNXJgZ9FpJ6q5lR/lYwxka42PzqswusUReRkEVmFd18iItJbRJ6v9poZYyKXBrlEoWAu3v4nMATIAFDVH4AzqrFOxpiIFtzDIKJ1Miao2WdV3VLifkRfWXmNMUeBKG0FBiOYoLhFRE4BVETqALfgutLGmKOQgtbi2edgus9/BMbgPYJnG9DHfTbGHLUkyCX6VNhSVNV04OoaqIsxJlrU4u5zMLPPnUTkIxHZJSI7ReRDEelUE5UzxkSoo3z2+U1gKtASaAW8C7xVnZUyxkSwoou3g1miUDBBUVR1iqoWuuV1ovY3wBhTFarqIbORqLx7nxu51VkichfwNl4wvAL4uAbqZoyJVLV49rm8iZbFHPr+gxsCvlPgoeqqlDEmskmUtgKDUd69zx1rsiLGmCgRxZMowQjqjhYR6QX0ABKL0lT1teqqlDEmkkXvJEowKgyKInI/MBAvKH4CnAt8g/fCaWPM0agWtxSDmX2+HO99Cb+o6nVAbyChWmtljIls/iCXKBRM9zlXVf0iUigi9fHewRqVF2/f/vCP9B+4h8yMeG688HgARv11AyeduZvCAmHH5kSeursrOXvjSGlQwL3j19C1114+/09zJjx0DABJ9Qp5/I3lxdts0iKPWdOa8cLDUXlKyD8g3HFpZwryY/AVwunnZzHiL78w+6NUpjzZgi3rEhn/yY907Z0LwJrv6/LMX7xX7ypwzR2/cOq5WQDcc1Undu+Mx1cIvU7K4aaHtxIbC/97rTEfvdqEmBhIqufj1se30L5rXrgOudJiYvyMf2YG6Rl1GTv211x99XLOGfITWVleW2Hy5N4sXNSKlJQ87r3nG7p23c3nX3RkwoSD74R/9JGZNGqUS15eLAD33ncmWVmJpe4v4hytD5kNsEhEGgAv4s1I7wMWVFRIRNridbFb4P1mTFTVZ468qpX3+QfNmfZ6K+589MfitO/nNuCVJzvg9wm/v3MDV9ywhZef6Eh+XgxTnmlH+y77ad9lf3H+3Jw4bhrat/jz+Pe/Z+5njWv0OKpSfILy2Ls/kVTPT2EB/HloF04clE2HYw/wfy9tZPzf2h6Sv0O3XJ77dC2xcZCRFseNZ3VjwG+yiI2De1/YSL0UP6rw0PUdmPNRAwYOzeTMS/ZwwYgMAObNqM8LY1vz8Js/h+Nwq8TFF//I5i2p1K1bUJz23/924/0Puh+SLz8/lilTjqN9h0zat886bDuPPX4y69ZF57+d2jz7XGH3WVX/pKqZqvpv4DfASNeNrkghcIeqdgcGAGNEpEflqls5Kxalsjfr0N+BJXMb4vd5v3prlqbQpEU+AHm5saxcnEp+XtmnqFX7XBo0LmDFovrVV+lqJgJJ9bx+TmGB4CsQRKBdlzzadj68NZdYV4l1p7AgL4bAJ8rVS/G24yuEwnwpvpirKB3gwP5Dy0SbJo330//E7cyYUXHPIC8vjpWrmpKfH1sDNathtfg2v/Iu3j6+vO9UdUl5G1bVHcAOt75XRFbjPWln1RHWtdqdfVkaX09vGnT+gRfsYvYnTYnWp4EU8fngpiHd2L6xDhdem86xx+8vN/+aJXV58s9t2bm1Dn99dnNxkAS458pOrF1al35n7uX0CzKL06e90oQPJjalIF947N311XQk1e+GG5Yw6eU+JCUVHJJ+4YXrGDx4A+vWNeLFl45n3746FW7r9tvn4/cJc79ty1tv9STa/x3VFuV1n58s5zsFBgW7ExHpAPQF5pfy3WhgNECi1At2k1Vu+B+34PMJs6YFHxR/fd4uHv9rt2qsVc2IjYUJX6xlX1YsD4zqwMY1iXQ49kCZ+Y89fj8vfrWWzesSePzWdpx4ZjZ1Er1mwcNv/Uz+AeGRm9qz9JtkTvj1PgAuui6di65L58sPGvDmMy34yzOba+TYqlL//tvIzExg/fpG/OpXacXpH3/cmbfe6omqMOKaZVz/hyU8/c8B5W7rscdPJiOjLklJBdx37zcMHrSRmV9Gz6XBR2X3WVXPLGcJJSAmA+8Dt6lqdin7maiq/VS1Xx0Jz0DzWUPT6D9wN4/d2Y1gf607dttHTKyyfmVy9VauBiWn+uh98j4WzkoJKn+7Lnkk1vWzce2h/93qJConn53FvBmph5UZODSTbz89PD0a9OixiwEDtvHqK9O462/f0vu4NP5y57dkZibh98egKkz/9Bi6dt1d4bYyMuoCkJsbz6yv2tO1W0Z1V7/qKN5tfsEsUSiYS3KOmIjE4wXEN1T1g+rc15E64fQ9DLt+Kw/c2IO8A8GP/Qy8IJ2vPw6+VRmpMjNi2ZflHXderrBkTkqpY4lFftlcB1+ht562NZ6tPyXSvE0+uTkxZKR5HQ9fISyYWb94O9t+PtiVXPBFfVp3jM6Z51df7cM1I4Zy7XUX8cijp/DDsuY8/sQpNGyYW5znlFO2smlT+UE/JsZP/freOYiN9XNS/+0Vlok4VTSmKCIvu0cSrghIGysi20RkqVvOC/jubhFZLyJrRWRIQPoJIrLcfTde3PtTRCRBRN5x6fNdr7VcQd3RciRcpSYBq1X1qeraTyj+9uQajuufRf2GhUz5egFTnm3HFaO3El/Hz7hXvP8ma35I4bn7OwPw6syF1E32ERfv55SzMrj3973Y/JP3C3/6ubv4v9E9w3YsVWV3WjxP3NoOv1/w++GMCzMZ8Jts5k5P5fn7WpOVEcf/u6YTx/TM5eG3fmbFgnq881xH4uIgJka5+eGtpDb2sWdXHGOv7URBvuDzQZ9T93HBiHQApr3SlCVzkomLg+QGhdwZhV3n8owatZROnfaAQlpaMuOfPbH4u1dfmUbdugXExfk55eSt3HvvmaTtrMffH5pFXJyfmBjl+6Ut+PTTY8J4BKGrwu7zq8BzHH4zyNOq+sQh+/QmaocDPfEeY/iFiHRVVR8wAW8Y7ju8m0zOAaYDo4A9qtpZRIYDj+I91KZMotX0fB8ROQ2YAyzn4GWc96jqJ2WVSY1togOSL6qW+tQG09fOCXcVIt65510V7ipEtO/WvEjW/u2V6tcmtG2rbW67Pai8P995x2JV7VdeHtd6+5+q9nKfxwL7SgmKdwOo6j/c5xnAWGAjMEtVj3XpVwIDVfWGojyqOk9E4oBfgKZaTuAL5jY/wXsdQSdVfVBE2gEtVLXcaxVV9RtsOs2Y2in4tlQTEVkU8Hmiqk4MotxNIjICWIR3ad8evKtXvgvIs9WlFbj1kum4v1sAVLVQRLKAxkB6WTsOZkzxeeBk4Er3eS/wryDKGWNqIdHgFyC9aCLVLcEExAnAMXgvydvBwSthSmtkaTnp5ZUpUzBB8SRVHQMcAHARu+KLsIwxtVc1zj6rapqq+lTVj3cnXX/31VYg8BarNsB2l96mlPRDyrjucypQ7uUBwQTFAhGJxUVXEWlK1N7qbYypCiG0FEPftkjLgI+XAEUz09OA4W5GuSPQBVjgbhTZKyID3HDfCODDgDIj3frlwJfljSdCcLPP44H/AM1EZJzb8H1BlDPG1FZVND8rIm/hPZqwiYhsBe4HBopIH7eXjbin/qvqShGZindXXCEwxs08A9yIN5OdhDfrPN2lTwKmiMh6vBbi8IrqFMx7n98QkcV4jw8TYKiqrq74cI0xtVIlWoGHbUr1ylKSJ5WTfxwwrpT0RUCvUtIPAMNCqVMws8/tgP3AR4Fpqlq7LjYzxgSvFt/mF0z3+WMOzvAkAh2BtXgXUBpjjkJSi2cVguk+/yrws3t6zg1lZDfGmKgW8m1+qrpERE6sOKcxptY6mrvPIvLngI8xwPHArmqrkTEmslXhREskCqalGPgcqUK8Mcb3q6c6xpiocLQGRXfRdrKq/qWG6mOMiQZHY1AUkTh3A3WZryUwxhx9hKN39nkB3vjhUhGZBrwL5BR9GakPjTXGVDMbU6QRkIH3Tpai6xUVsKBozNHqKA2KzdzM8woOfzxPLT4lxpgK1eIIUF5QjAWSOYLnkRljarejtfu8Q1UfrLGaGGOix1EaFO1VAsaYw+nRO/s8uMZqYYyJLkdjS1FVK36jtzHmqHS0jikaY0zpLCgaY4yjWFA0xpgignWfjTHmEBYUjTEmkAVFY4wJYEHRGGMce0qOMcaUYEHRGGMOOlpv86tx6vfj37s33NWIWKfdbG+WrUjGRbHhrkJEy/ulas5Pbe4+x4S7AsaYKKMhLBUQkZdFZKeIrAhIayQin4vIOve3YcB3d4vIehFZKyJDAtJPEJHl7rvxIiIuPUFE3nHp80WkQ0V1sqBojAldFQVF4FXgnBJpdwEzVbULMNN9RkR6AMOBnq7M8+7legATgNFAF7cUbXMUsEdVOwNPA49WVCELisaYkBTd0RLMUhFVnQ2UfPjMxcBktz4ZGBqQ/raq5qnqBmA90F9EWgL1VXWeqirwWokyRdt6Dxhc1IosS0SNKRpjooP4gx5UbCIiiwI+T1TViRWUaa6qOwBUdYeINHPprYHvAvJtdWkFbr1kelGZLW5bhSKSBTQG0svauQVFY0xoQnsgRLqq9quiPZf1apTyXpkS8utUrPtsjAlZVXWfy5DmusS4vztd+lagbUC+NsB2l96mlPRDyohIHJDK4d31Q1hQNMaEruomWkozDRjp1kcCHwakD3czyh3xJlQWuK72XhEZ4MYLR5QoU7Sty4Ev3bhjmaz7bIwJWVVdpygibwED8cYetwL3A48AU0VkFLAZGAagqitFZCqwCigExqiqz23qRryZ7CRgulsAJgFTRGQ9XgtxeEV1sqBojAldFQVFVb2yjK9KfUeUqo4DxpWSvgjoVUr6AVxQDZYFRWNMaI7it/kZY8xh7MnbxhhTUvlzFVHNgqIxJmTWUjTGmCL2Nj9jjDmUTbQYY0wAC4rGGFNEsYkWY4wJZBMtxhgTyIKiMcZ47OJtY4wJpBrKQ2ajjgVFY0zoam9MtKBojAmddZ+NMaaIAtZ9NsaYALU3JlpQNMaEzrrPxhgTwGafjTGmiD0lxxhjDvIu3q69UdGCojEmdPaUHGOMOchaikeBS67fxblXZaAqbFiTyJO3t2XkX39hwG+yKcgXdmyqw5O3tyMnOzbcVa1Wvz1zGReevBZV+HlHIx5+/dec2mszvz9vMe2b7+H6Jy5h7ZamALRotJc37p3K5p0NAFi5sRlPvHM6AHGxPv48bC59u+zArzDxoxP5+odO4TqsSvn7wFkMbL+R3blJXDTVe23wLScuYFCHDfhV2J2bxN2zBrFrfz1apWTz8RVvsyGzAQA/pDXngTm/BiA+xsd9p82hf6vt+FX454L+fL7hGO46ZS79W20DICmukEZJuZz0yqiwHGtQbEzxyIhIIjAbSHD7eU9V76+u/VVG4xYFDB2VzvUDu5F/IIZ7/72RgRdnsmR2Ci8/3BK/Txh173aG35zGpHGtwl3datMkNYfLf72S340bRn5BHA9e9wWDT/iJVRubcc9Lv+Gvw+ccVmZben2ue/Syw9JHDPmePXuTuPKhKxBR6tfNq4lDqBb/XduNN1f04pFBM4vTJi3tw/iF/QH4Xa9l/OmERcXBb0t2fS5977eHbeeG4xezOzeJc9++CkFJTTwAwCPfnlqc5+pey+neJL06D6cK1O57n2Oqcdt5wCBV7Q30Ac4RkQHVuL9KiY1TEhL9xMQqCUl+MtLiWfJ1Cn6fALB6cT2atCwIcy2rX2yMn4T4Qu9vnULSs+qxKa0hW1xrMFjnD1jLlM/7AKAqZOUkVn1la8iiHa3IzEs4JC2noE7xelJ8YVDbufTYNUz8/ngAFCHzQNJhec7vvI5P1neuRG1riGpwSxSqtpaiqiqwz32Md0tEnqWMX+J5b0JTpixcTd4BYcnXKSz5OuWQPEOu3M3XHzYITwVrSHpWPd6eeRzvP/gmeflxLFzThoVr2pRbpmXjvbz81/fJOVCHFz/ux7KfWpKc5LUK/3D+Ivp22c729Po89e6p7NlbtyYOo8bc2n8+F3ddy778OoycdnFxeuuUvbx/+bvk5MfzzIL+LP6lFSl1vHNyy4kL6N9qO5uz6/P3b04nI/fgOWmVvJc2KXv5blvrGj+WkGjVvY5ARDYCewEfUKiq/USkEfAO0AHYCPxWVfe4/HcDo1z+W1R1hks/AXgVSAI+AW51MShk1dlSRERiRWQpsBP4XFXnV+f+jlRyaiEnD8lm5EnduapvTxLr+hl06Z7i76+8JQ1fIXz5QYPwVbIGpCTlcdpxm/jt2CsZet/vSEwo4Ox+68rMn5Fdl8v+7yp+/9hlPPefAdw/8kvqJuYTG6M0b5jD8p+bM+qxy1ixoTljhn5Xg0dSM55ZcBKDXh/BR+u6cnWv5QDsyqnH4Nev4bL3hvHIt6fy+FlfUC8+n9gYPy2Tc1jySwsue38YS9Na8NeT5x2yvfM6r2fGz53wa7X+b1k1qraleKaq9lHVfu7zXcBMVe0CzHSfEZEewHCgJ3AO8LyIFA3yTwBGA13ccs6RHlq1nn1V9alqH6AN0F9EepXMIyKjRWSRiCwqIDzjTn1P38cvW+qQtTsOX6Ew95NUevTLAeCsYbvpf1Y2j97UHu8KrdqrX7dt7MhIIXNfEj5/DLN/6MivOqWVmb+gMJbs/V63eO2WpmxPr0/bpllk5SSQmxfH7GUdAZj1fSe6tc2okWMIh4/XdeHsTj8DUOCPJTPPOyer0puyJTuVDg0yyTyQyP6COL7Y4E02zfjpGHo02XXIds7tvJ6P13ep2cofKQ1yOTIXA5Pd+mRgaED626qap6obgPV4caUlUF9V57nW4WsBZUJWIz9JqpoJfEUp0VtVJ6pqP1XtF09Cya9rxM5t8XQ/PoeEJD+g9DltH5vXJ9BvYDa/HbOTsdd2JC83Cn69KyltTzI9O+wkIb4QUE7ouo2NvzQoM3+D5FxiXD+qVeNs2jTNYntGCiDMXdGOvl22A3BCt/K3E43ap2YWr5/ZYSM/72kIQMPEg+ekTUo27VOz2JpdHxC+2tSheJZ5QJutrHdlADqk7iE1IY+lac1r7BgqQ/z+oJYgKPCZiCwWkdEurbmq7gBwf5u59NbAloCyW11aa7deMv2IVOfsc1OgQFUzRSQJOAt4tLr2Vxlrv6/HnI8b8K8ZP+IrFNavSGL6642ZOGst8QnKP975CYA1i+sx/q7yx9ii2apNzZi1tCMv/+19fL4YftzamGnfdueM4zZw2+Xf0iA5l8f/+CnrtjXmjufPo/cxO/jD+Yvx+QWfX3jindPZ61qOEz48if83Yha3XDqPzH2J/OONgeE9uEp4YvDn9G+1nQaJB5j1u9d4btGJnNFuEx0bZOJXYfveFMbOOQOAfi23c8uJCyn0x+BXYezsM8hyLccnvxvAo4NmcnfCXHbnJnHvV2cW7+P8LuvdBEsU9EaUUC7ebiIiiwI+T1TViQGfT1XV7SLSDPhcRNaUs63STo6Wk35E5AjHIivesMhxeE3fWLwW6VRVfbC8MvWlkZ4kg6ulPrVBzmUnhbsKES+jZ+2+jrSyNk18igPbt1Qq8qbWa6UDetwQVN7PFo1dHDBWWC4RGYs3OXs9MFBVd7iu8Veq2s1NsqCq/3D5ZwBj8SZjZqnqsS79Slc+uEqWUG19QlVdpqp9VfU4Ve1VUUA0xkSRKphoEZF6IpJStA6cDawApgEjXbaRwIdufRowXEQSRKQj3oTKAtfF3isiA0REgBEBZUJmd7QYY0JXNT3M5sB/vDhGHPCmqn4qIguBqSIyCtgMDPN2qStFZCqwCigExqiqz23rRg5ekjPdLUfEgqIxJjShjSmWvRnVn4HepaRnAKWOo6nqOGBcKemLgMOubjkSFhSNMSELcmY5KllQNMaEKHpv4QuGBUVjTGgUC4rGGHOI2tt7tqBojAmdPWTWGGMCWVA0xhhHFXy1t/9sQdEYEzprKRpjTAALisYY4yhQi9/RYkHRGBMiBbUxRWOM8Sg20WKMMYewMUVjjAlgQdEYY4rYAyGMMeYgBezRYcYYE8BaisYYU8Ru8zPGmIMU1K5TNMaYAHZHizHGBLAxRWOMcVRt9tkYYw5hLUVjjCmiqM9XcbYoZUHRGBMae3SYMcaUYJfkGGOMRwG1lqIxxjhqD5k1xphD1OaJFtEImloXkV3ApnDXI0ATID3clYhgdn4qFmnnqL2qNq3MBkTkU7zjCka6qp5Tmf3VtIgKipFGRBapar9w1yNS2fmpmJ2j6BMT7goYY0wksaBojDEBLCiWb2K4KxDh7PxUzM5RlLExRWOMCWAtRWOMCWBB0RhjAlhQLIWIvCwiO0VkRbjrEolEpK2IzBKR1SKyUkRuDXedIomIJIrIAhH5wZ2fB8JdJxM8G1MshYicAewDXlPVXuGuT6QRkZZAS1VdIiIpwGJgqKquCnPVIoKICFBPVfeJSDzwDXCrqn4X5qqZIFhLsRSqOhvYHe56RCpV3aGqS9z6XmA10Dq8tYoc6tnnPsa7xVofUcKCoqkUEekA9AXmh7kqEUVEYkVkKbAT+FxV7fxECQuK5oiJSDLwPnCbqmaHuz6RRFV9qtoHaAP0FxEbhokSFhTNEXFjZe8Db6jqB+GuT6RS1UzgKyCqHopwNLOgaELmJhImAatV9alw1yfSiEhTEWng1pOAs4A1Ya2UCZoFxVKIyFvAPKCbiGwVkVHhrlOEORW4BhgkIkvdcl64KxVBWgKzRGQZsBBvTPF/Ya6TCZJdkmOMMQGspWiMMQEsKBpjTAALisYYE8CCojHGBLCgaIwxASwoRhER8bnLX1aIyLsiUrcS23pVRC536y+JSI9y8g4UkVOOYB8bReSwt76VlV4iz77yvi8l/1gRuTPUOhpTkgXF6JKrqn3ck3vygT8GfikisUeyUVX9QwVPuBkIhBwUjYlGFhSj1xygs2vFzRKRN4Hl7kEEj4vIQhFZJiI3gHcXiog8JyKrRORjoFnRhkTkKxHp59bPEZEl7lmAM90DH/4I3O5aqae7Ozbed/tYKCKnurKNReQzEfleRF4ApKKDEJH/ishi99zB0SW+e9LVZaaINHVpx4jIp67MHBE5tkrOpjFOXLgrYEInInHAucCnLqk/0EtVN7jAkqWqJ4pIAjBXRD7De5JNN+BXQHNgFfByie02BV4EznDbaqSqu0Xk38A+VX3C5XsTeFpVvxGRdsAMoDtwP/CNqj4oIucDhwS5Mvze7SMJWCgi76tqBlAPWKKqd4jI/7lt34T3Iqg/quo6ETkJeB4YdASn0ZhSWVCMLknucVTgtRQn4XVrF6jqBpd+NnBc0XghkAp0Ac4A3lJVH7BdRL4sZfsDgNlF21LVsp4peRbQw7sFGoD67mGzZwCXurIfi8ieII7pFhG5xK23dXXNAPzAOy79deAD91SeU4B3A/adEMQ+jAmaBcXokuseR1XMBYecwCTgZlWdUSLfeVT8oFMJIg94wy4nq2puKXUJ+r5RERmIF2BPVtX9IvIVkFhGdnX7zSx5DoypSjamWPvMAG50j/ZCRLqKSD1gNjDcjTm2BM4spew84Nci0tGVbeTS9wIpAfk+w+vK4vL1cauzgatd2rlAwwrqmgrscQHxWLyWapEYoKi1exVetzwb2CAiw9w+RER6V7APY0JiQbH2eQlvvHCJeC/eegGvR/AfYB2wHJgAfF2yoKruwhsH/EBEfuBg9/Uj4JKiiRbgFqCfm8hZxcFZ8AeAM0RkCV43fnMFdf0UiHNPk3kICHyHSQ7QU0QW440ZPujSrwZGufqtBC4O4pwYEzR7So4xxgSwlqIxxgSwoGiMMQEsKBpjTAALisYYE8CCojHGBLCgaIwxASwoGmNMgP8PB2ULG39zW4kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(logreg4_pipe, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model correctly predicts 52.78% of low damage.\n",
      "The model correctly predicts 84.25% of medium damage.\n",
      "The model correctly predicts 64.4% of complete destruction.\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, gs_preds)\n",
    "low_damage = cm[0][0] / (cm[0][0] + cm[0][1] + cm[0][2])\n",
    "medium_damage = cm[1][1] / (cm[1][0] + cm[1][1] + cm[1][2])\n",
    "complete_destruction = cm[2][2] / (cm[2][0] + cm[2][1] + cm[2][2])\n",
    "print(f'The model correctly predicts {round(low_damage*100, 2)}% of low damage.')\n",
    "print(f'The model correctly predicts {round(medium_damage*100, 2)}% of medium damage.')\n",
    "print(f'The model correctly predicts {round(complete_destruction*100, 2)}% of complete destruction.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
