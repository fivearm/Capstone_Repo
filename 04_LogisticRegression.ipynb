{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('Data/X_train.csv', index_col='building_id')\n",
    "X_test = pd.read_csv('Data/X_test.csv', index_col='building_id')\n",
    "y_train = pd.read_csv('Data/y_train.csv', index_col='building_id')\n",
    "y_test = pd.read_csv('Data/y_test.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = []\n",
    "for col in X_train.columns:\n",
    "    if col.startswith('has'):\n",
    "        binary_cols.append(col)\n",
    "\n",
    "cat_cols = list(X_train.select_dtypes(include='object').columns)\n",
    "\n",
    "integer_cols = ['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage', 'count_families']\n",
    "\n",
    "geo_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "\n",
    "all_cols = geo_cols + cat_cols + integer_cols + binary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {}\n",
    "def print_scores():\n",
    "    for key in score_dict.keys():\n",
    "        print(f'{key}, f1_micro_score: {round(score_dict[key][0],4)}, Run time: {round(score_dict[key][1],0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logreg0:  Basline Logistic Regression with no feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_pipe = imbPipeline([('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols),\n",
    "    ('categorical', ohe_pipe, cat_cols),\n",
    "    ('integer', 'passthrough', integer_cols),\n",
    "    ('geo', 'passthrough', geo_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg0_pipe = imbPipeline([\n",
    "    ('trans', transformer), \n",
    "    ('logreg', LogisticRegression(n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 72.52122688293457\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "f1_micro_logreg0 = cross_val_score(logreg0_pipe, X_train, y_train, scoring='f1_micro')\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')\n",
    "run_time_logreg0 = (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5691174213353799"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg0 = f1_micro_logreg0.mean()\n",
    "f1_micro_logreg0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg0, f1_micro_score: 0.5691, Run time: 73.0\n"
     ]
    }
   ],
   "source": [
    "score_dict['logreg0'] = [f1_micro_logreg0, run_time_logreg0]\n",
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a great score compared to our Random Forest models.  Let's move on with some feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logreg1: Try normalizing and scaling integer columns and dropping some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will drop the same features that I did for the random forest model after checking feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols_dropped = binary_cols.copy()\n",
    "for col in binary_cols_dropped:\n",
    "    if col.startswith('has_secondary'):\n",
    "        binary_cols_dropped.remove(col)\n",
    "binary_cols_dropped.append('has_secondary_use')\n",
    "\n",
    "cat_cols_dropped = cat_cols.copy()\n",
    "cat_cols_dropped.remove('legal_ownership_status')\n",
    "cat_cols_dropped.remove('plan_configuration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def log_transform(x):\n",
    "    return np.log(x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "ohe_pipe = imbPipeline([('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "integer_pipe = imbPipeline([\n",
    "    ('function', function_transformer),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols_dropped),\n",
    "    ('categorical', ohe_pipe, cat_cols_dropped),\n",
    "    ('geo', 'passthrough', geo_cols),\n",
    "    ('integer', integer_pipe, integer_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg1_pipe = imbPipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('logreg', LogisticRegression(n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 59.109540939331055\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "f1_micro_logreg1 = cross_val_score(logreg1_pipe, X_train, y_train, scoring='f1_micro')\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')\n",
    "run_time_logreg1 = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5723151701202354"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg1 = f1_micro_logreg1.mean()\n",
    "f1_micro_logreg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg0, f1_micro_score: 0.5691, Run time: 73.0\n",
      "logreg1, f1_micro_score: 0.5723, Run time: 59.0\n"
     ]
    }
   ],
   "source": [
    "score_dict['logreg1'] = [f1_micro_logreg1, run_time_logreg1]\n",
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a slight improvement.  Let's keep the scaling and normalization and add Target Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logreg2:  Try Target Encoding on the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "ohe_pipe = imbPipeline([('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "integer_pipe = imbPipeline([\n",
    "    ('function', function_transformer),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "target_pipe = imbPipeline([('target', TargetEncoder(cols=geo_cols))])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols_dropped),\n",
    "    ('categorical', ohe_pipe, cat_cols_dropped),\n",
    "    ('geo', target_pipe, geo_cols),\n",
    "    ('integer', integer_pipe, integer_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2_pipe = imbPipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('logreg', LogisticRegression(n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 58.27445602416992\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "f1_micro_logreg2 = cross_val_score(logreg2_pipe, X_train, y_train, scoring='f1_micro')\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')\n",
    "run_time_logreg2 = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7267587618316704"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg2 = f1_micro_logreg2.mean()\n",
    "f1_micro_logreg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg0, f1_micro_score: 0.5691, Run time: 73.0\n",
      "logreg1, f1_micro_score: 0.5723, Run time: 59.0\n",
      "logreg2, f1_micro_score: 0.7268, Run time: 58.0\n"
     ]
    }
   ],
   "source": [
    "score_dict['logreg2'] = [f1_micro_logreg2, run_time_logreg2]\n",
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Encoding greatly improves the model.  In fact, the f1-micro score is similar to the Random Forest models, with less run time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logreg3:  Use previous model with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "ohe_pipe = imbPipeline([('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "integer_pipe = imbPipeline([\n",
    "    ('function', function_transformer),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "target_pipe = imbPipeline([('target', TargetEncoder(cols=geo_cols))])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols_dropped),\n",
    "    ('categorical', ohe_pipe, cat_cols_dropped),\n",
    "    ('geo', target_pipe, geo_cols),\n",
    "    ('integer', integer_pipe, integer_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg3_pipe = imbPipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('logreg', LogisticRegression(n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 58.671720027923584\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "f1_micro_logreg3 = cross_val_score(logreg2_pipe, X_train, y_train, scoring='f1_micro')\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')\n",
    "run_time_logreg3 = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7267587618316704"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg3 = f1_micro_logreg3.mean()\n",
    "f1_micro_logreg3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg0, f1_micro_score: 0.5691, Run time: 73.0\n",
      "logreg1, f1_micro_score: 0.5723, Run time: 59.0\n",
      "logreg2, f1_micro_score: 0.7268, Run time: 58.0\n",
      "logreg3, f1_micro_score: 0.7268, Run time: 59.0\n"
     ]
    }
   ],
   "source": [
    "score_dict['logreg3'] = [f1_micro_logreg3, run_time_logreg3]\n",
    "print_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg2 == f1_micro_logreg3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SMOTE does not change the f1-micro score, so I will not use it going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the model with GridsearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a small grid search to see if we can improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 140.56797814369202\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "logreg_pipe_grid = {'logreg__C': [1e-3, 1e-2, 1, 1e2],\n",
    "                   'logreg__solver': ['lbfgs', 'saga']}\n",
    "logreg_gs = GridSearchCV(estimator=logreg2_pipe, param_grid=logreg_pipe_grid, \n",
    "                              scoring='f1_micro', verbose=1, cv=2)\n",
    "logreg_gs.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 0.01, 'logreg__solver': 'saga'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7227526221540035"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logreg4:  Use the grid searched hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use C=.01 and solver='saga'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "ohe_pipe = imbPipeline([('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "integer_pipe = imbPipeline([\n",
    "    ('function', function_transformer),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "target_pipe = imbPipeline([('target', TargetEncoder(cols=geo_cols))])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('binary', 'passthrough', binary_cols_dropped),\n",
    "    ('categorical', ohe_pipe, cat_cols_dropped),\n",
    "    ('geo', target_pipe, geo_cols),\n",
    "    ('integer', integer_pipe, integer_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg4_pipe = imbPipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('logreg', LogisticRegression(C=.01, solver='saga', n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 31.149606943130493\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "f1_micro_logreg4 = cross_val_score(logreg4_pipe, X_train, y_train, scoring='f1_micro')\n",
    "end = time.time()\n",
    "print(f'Run time: {end-start}')\n",
    "run_time_logreg4 = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7273931951905859"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro_logreg4 = f1_micro_logreg4.mean()\n",
    "f1_micro_logreg4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg0, f1_micro_score: 0.5691, Run time: 73.0\n",
      "logreg1, f1_micro_score: 0.5723, Run time: 59.0\n",
      "logreg2, f1_micro_score: 0.7268, Run time: 58.0\n",
      "logreg3, f1_micro_score: 0.7268, Run time: 59.0\n",
      "logreg4, f1_micro_score: 0.7274, Run time: 31.0\n"
     ]
    }
   ],
   "source": [
    "score_dict['logreg4'] = [f1_micro_logreg4, run_time_logreg4]\n",
    "print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is only a marginal score improvement, the saga solver does reduce the runtime by about half.  Let's call this the final Logistic Regression Model and check the model's performance on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the final model's performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-918c86191b6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogreg4_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlogreg4_test_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogreg4_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogreg4_test_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg4' is not defined"
     ]
    }
   ],
   "source": [
    "logreg4_preds = logreg4.predict(X_test)\n",
    "logreg4_test_score = f1_score(y_test, logreg4_preds, average='micro')\n",
    "logreg4_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not quite at the level of the Random Forest Classfier, this model performs remarkably well for it's speed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
